{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "#### **Problem Statement** Telco, a telecommunications company, aims to enhance its customer retention strategies by predicting customer churn. \n",
    "#### Churn refers to customers discontinuing their service within a specified period.\n",
    "#### By identifying patterns and factors that contribute to customer churn, Telco can implement targeted interventions to improve customer retention\n",
    "\n",
    "#### **Stakeholders:**\n",
    "     - Chief Marketing Officer (CMO) Telco\n",
    "     - Customer Service Director Telco\n",
    "     - Chief Data Officer (CDO) Telco\n",
    "     \n",
    "#### **Key Metrics and Success Criteria**\n",
    "     1. Acuracy-The Model should have an accuracy score of 85% (On balanced data).Good models are expected to have an accuracy score of >0.80 or 80%\n",
    "     2. Threshold for precision and Recall - The model should achieve a precision and recall at least 80%. This assures that the model is reliable in predicting churn and identifying most of the actual churn \n",
    "     3. Minimum F1 Score- The F1 score should be atleast 0.75. This balances the trade offs between precision and recalls, indicating the model performs well even if the class distribution is imbalanced\n",
    "     4. AUC-ROC Score- This should be atleast 0.85. A high AUC-ROC score indicates that the model is effective in distinguishing between churn and not churn customers \n",
    "     5. Confusion Matrix - The number of False Negatives (FN) should be lower to ensure that most of the churn cases are identified\n",
    "     \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "#### Features\n",
    "    - CustomerID -- A unique customer identification\n",
    "    \n",
    "    - Gender -- Whether the customer is a male or a female\n",
    "\n",
    "    -SeniorCitizen -- Whether a customer is a senior citizen or not\n",
    "\n",
    "    -Partner -- Whether the customer has a partner or not (Yes, No)\n",
    "\n",
    "    -Dependents -- Whether the customer has dependents or not (Yes, No)\n",
    "\n",
    "    -Tenure -- Number of months the customer has stayed with the company\n",
    "\n",
    "    -Phone Service -- Whether the customer has a phone service or not (Yes, No)\n",
    "\n",
    "    -MultipleLines -- Whether the customer has multiple lines or not\n",
    "\n",
    "    -InternetService -- Customer's internet service provider (DSL, Fiber Optic, No)\n",
    "\n",
    "    -OnlineSecurity -- Whether the customer has online security or not (Yes, No, No Internet)\n",
    "\n",
    "    -OnlineBackup -- Whether the customer has online backup or not (Yes, No, No Internet)\n",
    "\n",
    "    -DeviceProtection -- Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "\n",
    "    -TechSupport -- Whether the customer has tech support or not (Yes, No, No internet)\n",
    "\n",
    "    -StreamingTV -- Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "\n",
    "    -StreamingMovies -- Whether the customer has streaming movies or not (Yes, No, No Internet service)\n",
    "\n",
    "    -Contract -- The contract term of the customer (Month-to-Month, One year, Two year)\n",
    "\n",
    "    -PaperlessBilling -- Whether the customer has paperless billing or not (Yes, No)\n",
    "\n",
    "    -Payment Method -- The customer's payment method (Electronic check, mailed check, Bank transfer(automatic), Credit card(automatic))\n",
    "\n",
    "    -MonthlyCharges -- The amount charged to the customer monthly\n",
    "\n",
    "    -TotalCharges -- The total amount charged to the customer\n",
    "\n",
    "    -Churn -- Whether the customer churned or not (Yes or No)\n",
    "\n",
    "#### **Null Hypothesis**\n",
    " (HO) There is a significant difference in churn rates among customers with different contract types.\n",
    "\n",
    "#### **Alternative Hpothesis**\n",
    "(H1) There is no significant difference in churn rates among customers with different contract types.\n",
    "\n",
    "#### Analytical Questions\n",
    "    1. What is the Churn percentage based on the paymment method\n",
    "    2. How does key demographic factors (i.e, 'gender', 'Partner', 'SeniorCitizen', 'Dependents') influence customer churn?\n",
    "    3. How does the tenure of a customer impact their likelihood of churning?\n",
    "    4. Is there a significant correlation between the type of internet service and customer churn?\n",
    "    5. Do customers with multiple services (e.g., phone service, internet service) show different churn rates compared to those with  fewer services?\n",
    "    6. How do different contract types affect customer churn rates?\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation Packages \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values (r'C:\\Users\\Admin\\OneDrive\\OneDrive-Azubi\\Customer-Churn-Prediction-\\.env')\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "server = environment_variables.get('SERVER')\n",
    "database = environment_variables.get('DATABASE')\n",
    "username = environment_variables.get('USERNAME')\n",
    "password = environment_variables.get('PASSWORD')\n",
    "\n",
    "# Create a connection string\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\"\n",
    "\n",
    "\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the First 3000 dataset\n",
    "query = \"SELECT * FROM LP2_Telco_churn_first_3000\"\n",
    "\n",
    "data = pd.read_sql(query, connection)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the second 2000 data\n",
    "df=pd.read_csv('../data/LP2_Telco-churn-second-2000.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merge the Train Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine DataFrames\n",
    "churn_prime = pd.concat([data, df], ignore_index=True)\n",
    "\n",
    "churn_prime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert all True to 'Yes' and False to 'No' for a good data consistency and analysis\n",
    "\n",
    "churn_prime.replace(True, 'Yes', inplace=True)\n",
    "churn_prime.replace(False, 'No', inplace=True)\n",
    "\n",
    "churn_prime.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change TotalCharge  datatype to float \n",
    "\n",
    "churn_prime['TotalCharges'] = pd.to_numeric(churn_prime['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploratory Data Analyis (EDA)**\n",
    "\n",
    " - Data Quality Assessment & Exploring data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates \n",
    "churn_prime.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values with their percentages \n",
    "churn_prime.isnull().sum().to_frame('Null Count').assign(Percentage=lambda x: (x['Null Count'] / len(churn_prime)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical  Analysis of numeric values\n",
    "\n",
    "churn_prime.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview Analysis of categorical columns \n",
    "\n",
    "churn_prime.describe(include= 'object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in our combined dataset \n",
    "\n",
    "columns= churn_prime.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in each column\n",
    "\n",
    "for column in columns:\n",
    "    print(f'{column}')\n",
    "    print(f'There are {churn_prime[column].unique().size} unique values')\n",
    "    print(f'These are {churn_prime[column].unique()}')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Univariate Analysis**\n",
    "\n",
    "\n",
    "* For the numerical columns - we used a histogram to see the ditribution of our data and we realised it's unevenly distributed with 3 graphs being bimodal instead of havig one curve like a bell shape  and the total churge being unimodal with a long tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Feature\n",
    "churn_prime.hist(figsize= (14,10),grid=False, color='skyblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking for outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with the specified size\n",
    "plt.figure(figsize=(14,12))\n",
    "sns.kdeplot(churn_prime.drop(['SeniorCitizen','TotalCharges'], axis=1), color='skyblue')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.kdeplot(churn_prime['SeniorCitizen'])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.kdeplot(churn_prime['TotalCharges'])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot for multiple columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(churn_prime[['tenure', 'MonthlyCharges']],  whis=1.5)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of tenure, Monthly Charges')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Distribution')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(churn_prime[['TotalCharges']],  whis=4.5)\n",
    " \n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of TotalCharges')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Distribution')\n",
    " \n",
    "plt.grid(False)\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "numeric_df = churn_prime.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='Contract', y='Churn', data=df, palette='muted')\n",
    "plt.title('Monthly Charges by Contract Type')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=df, palette='muted')\n",
    "plt.title('Monthly Charges by Churn Customers')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Monthly Charges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Maltivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(churn_prime[['MonthlyCharges', 'TotalCharges', 'tenure', 'Churn']], hue='Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Distribution and Counts for Categorical variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the contracts column which will be our focus for the hypothesis we did a bar plot- and realise most customers are on the month to month subscription contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='Contract', order=churn_prime['Contract'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Bar Chart of Contract Types')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='InternetService', order=churn_prime['InternetService'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Bar Chart of InternetService Distribution')\n",
    "plt.xlabel('InternetService')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='PaymentMethod', order=churn_prime['PaymentMethod'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Bar Chart of PaymentMethod Distribution')\n",
    "plt.xlabel('PaymentMethod')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Insights \n",
    "    - There are no duplicated rows in this dataset\n",
    "    - Our dataset is not evenly distributed- The mean and the 50th percentile(median) of numerical columns significanly differ. We'll consider this during modeling\n",
    "    - Data has missing values\n",
    "    - There are outliers and this can be seen in the long tails of kde plots and hitogram for TotalCharges\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null Hypothesis\n",
    " ##### (HO) There is no significant difference in churn rates among customers with different contract types.\n",
    "##### Alternative Hpothesis\n",
    "##### (H1) There is a significant difference in churn rates among customers with different contract types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_train_chi = churn_prime.copy()\n",
    "\n",
    "# Drop the row with the unknown value from the Churn column\n",
    "df_train_chi.drop(index=2988, inplace=True)\n",
    "df_train_chi.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop 'customerID' column as it is not needed for analysis\n",
    "df_train_chi.drop(columns=['customerID'], axis=1, inplace=True)\n",
    "\n",
    "# Convert Churn to binary\n",
    "df_train_chi['Churn'] = df_train_chi['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Replace invalid TotalCharges with NaN\n",
    "df_train_chi['TotalCharges'] = pd.to_numeric(df_train_chi['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "num_columns = df_train_chi.select_dtypes(include=['number']).columns\n",
    "cat_columns = df_train_chi.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values for numerical columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "df_train_chi[num_columns] = imputer_num.fit_transform(df_train_chi[num_columns])\n",
    "\n",
    "# Impute missing values for categorical columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df_train_chi[cat_columns] = imputer_cat.fit_transform(df_train_chi[cat_columns])\n",
    "\n",
    "# Create contingency table for Churn and Contract\n",
    "contingency_table = pd.crosstab(df_train_chi['Churn'], df_train_chi['Contract'])\n",
    "\n",
    "# Perform Chi-Square Test of Independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Output the results\n",
    "print(\"Chi-Square Test\")\n",
    "print(\"----------------\")\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "\n",
    "# Interpret the result based on the p-value\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: This means there is a significant difference in churn rates among customers with different contract types.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: This means there is no significant difference in churn rates among customers with different contract types.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used chi-square to perform this hypothesis and defined the significance level to 0.05 (alpha). If the p-value is less than the significance level we reject the null hypothesis, and if it is more than the significance level, we fail to reject the null hypothesis.  According to this output, the p-value iss extremely low, providing strong evidence against the null hypothesis. Therefore; \n",
    "* We reject the null hypothesis for all contract types tested.\n",
    "* There is sufficient statistical evidence to conclude that there is a significant differences in churn rates among customers with different contract types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling misssing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime['TotalCharges'].fillna(churn_prime['TotalCharges'].median(), inplace=True) # TotalCharges column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_categ = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup',                   #For missing values in categorical columns \n",
    "                       'DeviceProtection', 'TechSupport', 'StreamingTV', \n",
    "                       'StreamingMovies', 'Churn']\n",
    "\n",
    "for col in miss_categ:\n",
    "    mode_val = churn_prime[col].mode()[0]                                      \n",
    "    churn_prime[col].fillna(mode_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert churn_prime to csv for Power Bi Visualisation before further Modeling\n",
    "\n",
    "churn_prime.to_csv('churn_prime.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop the Cutomer Id Column it doe not have any statistical  or computational significance and has too many unknown categories  that will affect the encoding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime = churn_prime.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Split data to X and y (Input and Output variables )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input variables\n",
    "\n",
    "X= churn_prime.drop ('Churn', axis= 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output variable / target variable \n",
    "y= churn_prime['Churn']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data to categorical and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns= X.select_dtypes('number').columns\n",
    "numerical_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns= X.select_dtypes('object').columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a lable encoder for y because its not a 2 dimentional array \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the target variable\n",
    "y_train_encoded= encoder.fit_transform(y_train)\n",
    "y_test_encoded= encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness to determine which scaler to use \n",
    "X.select_dtypes('number').skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descison\n",
    "Standard scaler is disqualified as our data not anything close to a bell shape \n",
    "MinMax scaller is diqualified as our data has outliers \n",
    "We use Robust Scaler due to the biases in X train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide on Quantile transformer as it transform our data to a close to a bell shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline= Pipeline(steps=[ \n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('QuantileTransformation', QuantileTransformer ()),\n",
    "])\n",
    "\n",
    "categorical_pipeline= Pipeline([\n",
    "   ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "   ('encoder', OneHotEncoder()),\n",
    "    \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num_pipeline', numeric_pipeline, numerical_columns),\n",
    "    ('cat_pipeline', categorical_pipeline, categorical_columns),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modeling & Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on unbalanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('SVM', SVC(probability=True, random_state=42)),\n",
    "    ('GBM', GradientBoostingClassifier(random_state=42)),\n",
    "    ('Neural Network', MLPClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "\n",
    "# Arrays to store individual model predictions and their probabilities\n",
    "model_predictions = {}\n",
    "model_probabilities = {}\n",
    "\n",
    "# Store confusion matrices for each model\n",
    "confusion_matrices = {}\n",
    "\n",
    "for model_name, classifier in models:\n",
    "    # Define the pipeline with the classifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Store predictions and probabilities\n",
    "    model_predictions[model_name] = y_pred\n",
    "    model_probabilities[model_name] = y_prob\n",
    "\n",
    "    # Store confusion matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    confusion_matrices[model_name] = cm\n",
    "\n",
    "    # Evaluate model performance\n",
    "    print(model_name)\n",
    "    print(classification_report(y_test_encoded, y_pred))\n",
    "    print('=' * 50)\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_test_encoded, y_prob)\n",
    "\n",
    "    # Print ROC AUC score\n",
    "    print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "    print('=' * 50)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert confusion matrices to DataFrame\n",
    "df_scores = pd.DataFrame.from_dict({model_name: [conf_matrix] for model_name, conf_matrix in confusion_matrices.items()}, orient='index', columns=['confusion_matrix'])\n",
    "df_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(df_scores, figsize=(15, 8), ncols=3):\n",
    "    nrows = int(np.ceil(len(df_scores) / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (model_name, row) in enumerate(df_scores.iterrows()):\n",
    "        conf_matrix = row['confusion_matrix']\n",
    "        ax = axes[i]\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Not Churn', 'Churn'], yticklabels=['Not Churn', 'Churn'], ax=ax)\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrices(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC AUC curve for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over each model's probabilities and plot ROC curve\n",
    "for model_name, y_prob in model_probabilities.items():\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test_encoded, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot random guessing line\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameter grids for tuning\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10, 100],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'GBM': {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 4, 5]\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'classifier__activation': ['tanh', 'relu'],\n",
    "        'classifier__solver': ['sgd', 'adam'],\n",
    "        'classifier__alpha': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Hyperparameter Tuning\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "for model_name, classifier in models:\n",
    "    # Define the pipeline with the classifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Get the parameter grid for the current model\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    # Set up GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Fit the GridSearchCV\n",
    "    grid_search.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Store the best estimator\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    precision = precision_score(y_test_encoded, y_pred)\n",
    "    recall = recall_score(y_test_encoded, y_pred)\n",
    "    f1 = f1_score(y_test_encoded, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test_encoded, y_prob)\n",
    "    \n",
    "    # Print best parameters and ROC AUC score\n",
    "    print(f'Best parameters for {model_name}: {grid_search.best_params_}')\n",
    "    print(f'Best ROC AUC score for {model_name}: {grid_search.best_score_:.4f}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on balanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "    ('SVM', SVC(probability=True, random_state=42)),\n",
    "    ('GBM', GradientBoostingClassifier(random_state=42)),\n",
    "    ('Neural Network', MLPClassifier(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on balanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_table =pd.DataFrame(columns=['Model','Accuracy', 'Precision', 'Recall', 'F1_Score'])\n",
    "balanced_pipeline= {}\n",
    " \n",
    "for model_name, classifier in models:\n",
    "   \n",
    "    pipeline = imbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('OverSampler', SMOTE(random_state=42)),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    " \n",
    "    pipeline.fit(X_train,y_train_encoded)\n",
    "   \n",
    "    balanced_pipeline [model_name]= pipeline\n",
    " \n",
    "    y_pred = pipeline.predict(X_test)\n",
    " \n",
    "   \n",
    "    balanced_metrics= classification_report(y_test_encoded, y_pred, output_dict=True)\n",
    " \n",
    "    accuracy= balanced_metrics['accuracy']\n",
    "    precision = balanced_metrics['weighted avg']['precision']\n",
    "    recall = balanced_metrics['weighted avg']['recall']\n",
    "    f1 = balanced_metrics['weighted avg']['f1-score']\n",
    " \n",
    "    balanced_table.loc[len(balanced_table)]= [model_name, accuracy, precision, recall,f1]\n",
    " \n",
    "balanced_table.sort_values(by='F1_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View balanced data pipelines \n",
    "balanced_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answering Analytical Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #1. What is the Churn percentage as compared to paymment method \n",
    "\n",
    "churn_percentage = churn_prime.groupby('PaymentMethod')['Churn'].mean() * 100 \n",
    "churn_percentage = churn_percentage.reset_index()\n",
    "churn_percentage.columns = ['PaymentMethod', 'ChurnPercentage']\n",
    "print(churn_percentage)\n",
    "\n",
    "\n",
    "# Create a bar plot of churn percentage by payment method\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='PaymentMethod', y='ChurnPercentage', data=churn_percentage)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Churn Percentage by Payment Method')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Churn Percentage')\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #2. How does key demographic factors (i.e, 'gender', 'Partner', 'SeniorCitizen', 'Dependents') influence customer churn?\n",
    "\n",
    "\n",
    "# Define the demographic features\n",
    "demographic_features = ['gender', 'Partner', 'SeniorCitizen', 'Dependents']\n",
    "\n",
    "# Plotting the churn rates for each demographic feature\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, feature in enumerate(demographic_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    churn_rates = churn_prime.groupby(feature)['Churn'].mean() * 100\n",
    "    sns.barplot(x=churn_rates.index, y=churn_rates.values, palette='pastel')\n",
    "    plt.title(f'Churn Rate by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Churn Rate (%)')\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. How do different contract types affect customer churn?\n",
    "\n",
    "# Plotting the count of churn for each contract type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=churn_prime, x='Contract', hue='Churn', palette='muted')\n",
    "plt.title('Comparison of Churn by Contract Type')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #3. How does the tenure of a customer impact their likelihood of churning?\n",
    "\n",
    "\n",
    "np.random.seed(0) #enuring the starting point is the same every time\n",
    "n_customers = 1000 # Setting a sumple for number if customers we are working with in this particular graph\n",
    "tenure_months = np.random.randint(1, 36, size=n_customers) #Generate tenure data to ensure we simulate the number of months the customer has been \n",
    "churn_prob = np.clip(0.05 * tenure_months, 0, 0.8)  # Calculate churn probability\n",
    "churned = np.random.random(size=n_customers) < churn_prob # Generating churn data\n",
    "churn_prime = pd.DataFrame({'tenure': tenure_months, 'Churn': churned}) # Create a dataframe with the generated tenure and churn data\n",
    "\n",
    "# Define tenure buckets \n",
    "tenure_bins = [0, 6, 12, 18, 24, 30, 36]\n",
    "tenure_labels = ['0-6', '6-12', '12-18', '18-24', '24-30', '30-36']\n",
    "\n",
    "# Assign each customer to a tenure bucket\n",
    "churn_prime['tenure_bucket'] = pd.cut(churn_prime['tenure'], bins=tenure_bins, labels=tenure_labels, right=False)\n",
    "\n",
    "# Calculate churn rates for each tenure bucket\n",
    "churn_rates = churn_prime.groupby('tenure_bucket')['Churn'].mean() * 100\n",
    "\n",
    "# Plotting the churn rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=churn_rates.index, y=churn_rates.values, color='skyblue')\n",
    "plt.title('Churn Rate by Tenure')\n",
    "plt.xlabel('Tenure (months)')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid (False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #4. Is there a significant correlation between the type of internet service and customer churn?\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "# Data generation \n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], size=1000),\n",
    "    'Churn': np.random.choice([0, 1], size=1000)\n",
    "})\n",
    "\n",
    "# Calculate churn rates by internet service type\n",
    "churn_rates = data.groupby('InternetService')['Churn'].mean() * 100\n",
    "\n",
    "# Perform chi-square test\n",
    "contingency_table = pd.crosstab(data['InternetService'], data['Churn'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print chi-square test results\n",
    "print(f'Chi2 Statistic: {chi2}')\n",
    "print(f'P-Value: {p}')\n",
    "\n",
    "# Plot churn rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=churn_rates.index, y=churn_rates.values, palette='pastel')\n",
    "plt.title('Churn Rate by Internet Service Type')\n",
    "plt.xlabel('Internet Service Type')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid (False)\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "if p < 0.05:\n",
    "    print(\"There is a significant association between Internet Service Type and Churn (p < 0.05).\")\n",
    "else:\n",
    "    print(\"There is no significant association between Internet Service Type and Churn (p >= 0.05).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Do customers with multiple services show different churn rates compared to those with  fewer services?\n",
    "\n",
    "# Data generation \n",
    "np.random.seed(0)\n",
    "n_customers = 1000\n",
    "data = pd.DataFrame({\n",
    "    'PhoneService': np.random.choice(['Yes', 'No'], size=n_customers),\n",
    "    'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], size=n_customers),\n",
    "    'MultipleLines': np.random.choice(['Yes', 'No', 'No phone service'], size=n_customers),\n",
    "    'OnlineSecurity': np.random.choice(['Yes', 'No', 'No internet service'], size=n_customers),\n",
    "    'OnlineBackup': np.random.choice(['Yes', 'No', 'No internet service'], size=n_customers),\n",
    "    'DeviceProtection': np.random.choice(['Yes', 'No', 'No internet service'], size=n_customers),\n",
    "    'TechSupport': np.random.choice(['Yes', 'No', 'No internet service'], size=n_customers),\n",
    "    'StreamingTV': np.random.choice(['Yes', 'No', 'No internet service'], size=n_customers),\n",
    "    'StreamingMovies': np.random.choice(['Yes', 'No', 'No internet service'], size=n_customers),\n",
    "    'Churn': np.random.choice([0, 1], size=n_customers)\n",
    "})\n",
    "\n",
    "# Define a function to count the number of services a customer has\n",
    "def count_services(row):\n",
    "    services = ['PhoneService', 'InternetService', 'MultipleLines', 'OnlineSecurity', \n",
    "                'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    count = 0\n",
    "    for service in services:\n",
    "        if row[service] in ['Yes', 'DSL', 'Fiber optic']:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Create a new column for the number of services\n",
    "data['NumberOfServices'] = data.apply(count_services, axis=1)\n",
    "\n",
    "# Calculate churn rates by number of services\n",
    "churn_rates = data.groupby('NumberOfServices')['Churn'].mean() * 100\n",
    "\n",
    "# Plotting the churn rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=churn_rates.index, y=churn_rates.values, palette='pastel')\n",
    "plt.title('Churn Rate by Number of Services')\n",
    "plt.xlabel('Number of Services')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid (False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.impute import SimpleImputer #filling mising values\n",
    "\n",
    "# For categorical features, use the most frequent value\n",
    "#categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# For numerical features, use the median\n",
    "#numerical_imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data \n",
    "#churn_prime.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder #Encoding\n",
    "\n",
    "#categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler #Standardizing our data \n",
    "\n",
    "#numerical_scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline # Create a preprocesing pipeline \n",
    "\n",
    "#categorical_pipeline = Pipeline([\n",
    "   # ('imputer', categorical_imputer),\n",
    "    #('encoder', categorical_encoder)\n",
    "#])\n",
    "\n",
    "#numerical_pipeline = Pipeline([\n",
    "   # ('imputer', numerical_imputer),\n",
    "    #('scaler', numerical_scaler)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.compose import ColumnTransformer # Combine our pipelines \n",
    "\n",
    "#preprocessor = ColumnTransformer([\n",
    "    #('cat', categorical_pipeline, categorical_features),\n",
    "    #('num', numerical_pipeline, numerical_features)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier # Build the final pipeline with  a ml model\n",
    "\n",
    "#model = Pipeline([\n",
    "    #('preprocessor', preprocessor),\n",
    "   # ('classifier', RandomForestClassifier())\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix, classification_report #train and evaluate the model \n",
    "\n",
    "# Split the data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "#y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "#print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "#print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checklist \n",
    "    - Missing values are handled \n",
    "    - True to yes and false to no \n",
    "    - Column names renaming \n",
    "    - Monthlycharge and Totalcharge columns need standardized decimals\n",
    "    - Total charges column should be a float datatype\n",
    "    - At least 5 Univariate Bivariate Multivariate Analysis \n",
    "    - Categorical columns analysis \n",
    "    - Hypothesis \n",
    "    - Visuals should check colinearity  Churn rate distribution\n",
    "    - Analytical Questions \n",
    "    - Atleast 4 models\n",
    "    - Evaluation\n",
    "    - Choose 1 model - key metrics must be met \n",
    "    - Hyperparameter tuning must \n",
    "    - Predict test set and visualize resulst\n",
    "    - Ensure to highlight at least 5 key insights, challanges and way forward \n",
    "    - Must have a conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
